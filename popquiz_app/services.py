# services.py
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆ Quiz çš„æ ¸å¿ƒé€»è¾‘ï¼ˆDeepSeek + spaCyï¼‰
"""
from __future__ import annotations

import logging
import re
from datetime import datetime
from typing import Any, Dict, List, Optional

import spacy
from transformers import pipeline

# â”€â”€â”€â”€â”€ æ—¥å¿— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_LOGGER = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s"
)

# â”€â”€â”€â”€â”€ ä¾èµ–åŠ è½½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_LOGGER.info("ğŸ”„  Loading spaCy model â€¦")
_NLP = spacy.load("en_core_web_sm")

_LOGGER.info("ğŸ”„  Loading DeepSeek pipeline (cpu) â€¦")
_PIPE = pipeline(
    task="text-generation",
    model="deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    device=-1,                # CPU
    trust_remote_code=True,
)
_LOGGER.info("âœ…  DeepSeek pipeline loaded")

# â”€â”€â”€â”€â”€ æ­£åˆ™å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_RE_Q   = re.compile(r"[é—®é¡Œ]\s*[:ï¼š]\s*(.+)", re.I)
_RE_OPT = re.compile(r"^\s*([ABCD])[\.\:ã€\)]\s*(.+)", re.M)
_RE_ANS = re.compile(r"æ­£ç¡®ç­”æ¡ˆ?\s*[:ï¼š]\s*([ABCD])", re.I)


def _parse_reply(txt: str) -> Optional[Dict[str, Any]]:
    """ä» LLM è¾“å‡ºä¸­æŠ½å– {question, options[4], answer}"""
    # å»æ‰ DeepSeek çš„ <think>
    if "</think>" in txt:
        txt = txt.split("</think>", 1)[-1]

    # â€”â€”â€” â‘  ä¸¥æ ¼æ­£åˆ™ â€”â€”â€”
    q    = _RE_Q.search(txt)
    opts = _RE_OPT.findall(txt)
    ans  = _RE_ANS.search(txt)
    if q and len(opts) >= 4 and ans:
        opt_dict = {k: v.strip() for k, v in opts[:4]}
        return {
            "question": q.group(1).strip(),
            "options":  [opt_dict[k] for k in "ABCD"],
            "answer":   ans.group(1).strip(),
        }

    # â€”â€”â€” â‘¡ fallback ç²—åŒ¹é… â€”â€”â€”
    lines      = [l.strip() for l in txt.splitlines() if l.strip()]
    cand_q     = next((l for l in lines if "?" in l or "ï¼Ÿ" in l), "")
    cand_opts  = [l for l in lines if re.match(r"^[ABCD]", l)]
    cand_ans   = next((l for l in lines if "æ­£ç¡®" in l), "")
    if cand_q and len(cand_opts) >= 4 and cand_ans:
        return {
            "question": re.sub(r"^[^\w]*", "", cand_q),
            "options":  [re.sub(r"^[ABCD][^\w]+", "", o) for o in cand_opts[:4]],
            "answer":   re.search(r"[ABCD]", cand_ans).group(0),
        }
    return None


# â”€â”€â”€â”€â”€ å¤–éƒ¨ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_key_sentences(text: str, *, limit: int = 1) -> List[str]:
    """ç”¨ spaCy æŠ½å–å‰Â limitÂ å¥ä½œä¸ºâ€œé‡ç‚¹å¥å­â€"""
    doc = _NLP(text)
    sent_list = [s.text.strip() for s in doc.sents if s.text.strip()]
    return sent_list[:limit]


def generate_quiz_with_deepseek(
        text: str,
        *,
        num_questions: int = 1,
        max_new_tokens: int = 256,
        collection=None,                      # ä¼  Mongo collection åˆ™è½åº“ï¼›None=ä¸è½åº“
        **gen_kwargs,                         # é€ä¼ ç»™ pipelineï¼Œä¾‹å¦‚ temperature=0.7
) -> List[Dict[str, Any]]:
    """
    ä»æ–‡æœ¬é‡Œç”Ÿæˆ â‰¤Â num_questionsÂ é“é€‰æ‹©é¢˜
    è¿”å›å½¢å¦‚ [{"quiz_id": "...", "quiz": {...}}, â€¦]
    """
    sentences = extract_key_sentences(text, limit=num_questions)
    quizzes: List[Dict[str, Any]] = []

    for sentence in sentences:
        # â€”â€” ä¿é™©æˆªæ–­ï¼Œé˜² prompt è¿‡é•¿ â€”â€”
        if len(sentence) > 512:
            sentence = sentence[:509] + "â€¦"

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šå‡ºé¢˜ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹åˆ—å†…å®¹ï¼Œç”Ÿæˆä¸€é“**å•é¡¹é€‰æ‹©é¢˜**ï¼Œç”¨æ¥è€ƒå¯Ÿè¯¥å†…å®¹ä¸­çš„**å…³é”®çŸ¥è¯†ç‚¹**ã€‚

è¦æ±‚ï¼š
1. åªè€ƒå¯Ÿæœ€æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€‚
2. é—®é¢˜è¦èƒ½åˆ¤å®šå­¦ç”Ÿæ˜¯å¦ç†è§£æ ¸å¿ƒå†…å®¹ã€‚
3. **æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆ**ï¼Œå…¶ä»–ä¸‰ä¸ªé€‰é¡¹è¦è¿·æƒ‘ä½†é”™è¯¯ã€‚
4. ä¸¥æ ¼ä½¿ç”¨ä¸‹åˆ—æ ¼å¼ï¼š

å†…å®¹ï¼š
{sentence}

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå¾ªï¼‰ï¼š
é—®é¢˜: â€¦
é€‰é¡¹:
A. â€¦
B. â€¦
C. â€¦
D. â€¦
æ­£ç¡®ç­”æ¡ˆ: A/B/C/D
"""

        # â€”â€”â€” è°ƒç”¨ LLMï¼ˆå¸¦ max_new_tokens & é¢å¤–å‚æ•°ï¼‰ â€”â€”â€”
        reply_raw = _PIPE(
            prompt,
            do_sample=False,
            max_new_tokens=max_new_tokens,
            **gen_kwargs,
        )[0]["generated_text"]

        parsed = _parse_reply(reply_raw)

        # å¦‚è§£æå¤±è´¥ â†’ å°è¯•ä¸€æ¬¡æ¸©å’Œé‡‡æ ·é‡è¯•
        if not parsed:
            _LOGGER.warning("âš ï¸  è§£æå¤±è´¥ï¼Œé‡è¯•ä¸€æ¬¡ â€¦")
            reply_raw = _PIPE(
                prompt,
                do_sample=True,
                temperature=0.7,
                max_new_tokens=max_new_tokens,
                **gen_kwargs,
            )[0]["generated_text"]
            parsed = _parse_reply(reply_raw)

        if not parsed:
            _LOGGER.warning("âš ï¸  ä»è§£æå¤±è´¥ï¼Œè·³è¿‡æœ¬å¥ã€‚")
            continue

        # â€”â€”â€” å…¥åº“ï¼ˆå¯é€‰ï¼‰ â€”â€”â€”
        doc = {**parsed, "created_at": datetime.utcnow()}
        if collection is not None:
            _id = collection.insert_one(doc).inserted_id  # type: ignore[attr-defined]
            quiz_id = str(_id)
        else:
            quiz_id = "local-" + datetime.utcnow().isoformat(timespec="seconds")

        quizzes.append({"quiz_id": quiz_id, "quiz": parsed})

    return quizzes
