from services import generate_quiz_with_deepseek

# 测试文本内容
test_text = """
AI 如何运作？
虽然不同 AI 技术的具体情况有所不同，但核心原则都是围绕数据展开。AI 系统会通过接触大量数据来学习和改进，以识别人类可能会忽视的模式和关系。

这个学习过程通常涉及算法，算法是指指导 AI 分析和决策的一组规则或指令。机器学习是 AI 的一个热门细分领域，其算法基于已加标签或未加标签的数据进行训练，以做出预测或对信息进行分类。

深度学习是另一个专精领域，它利用多层人工神经网络来处理信息，模仿人类大脑的结构和功能。通过持续学习和适应，AI 系统越来越擅长执行从图片识别到语言翻译等特定任务。

想要了解如何开始使用 AI？参加面向初学者的生成式 AI 简介免费课程。

人工智能的类型
人工智能可以采用多种方式进行组织，具体取决于开发阶段或正在执行的操作。

例如，AI 开发通常分为四个阶段。

反应式机器：有限的 AI，仅根据预编程规则对不同类型的刺激做出反应。不使用记忆，因此无法通过新数据进行学习。1997 年击败国际象棋冠军加里·卡斯帕罗夫的 IBM 深蓝超级计算机就是反应式机器的一个例子。
有限记忆：人们认为大多数现代 AI 都拥有有限的记忆。它可以通过新数据（通常是通过人工神经网络或其他训练模型）进行训练，从而使用记忆随着时间的推移进行改进。深度学习是机器学习的一个细分领域，它被视为具有有限记忆的人工智能。
心智理论：心智理论 AI 目前不存在，但研究正在实现其可能性。它描述了可以模拟人类心智并具有与人类相同的决策能力的 AI，包括识别和记忆情感以及在社交场合中像人类一样做出反应。
自我意识：自我意识 AI 比心智理论 AI 前进了一步，它描述了一种神秘的机器，这种机器知道自己的存在并具有人类的智力和情感能力。与心智理论 AI 一样，自我意识 AI 目前也不存在。
在对人工智能类型进行广泛分类时，一种更有用的方法是按照机器可以做什么来分类。我们目前所说的所有人工智能都被认为是“窄”(narrow) 人工智能，因为它只能根据其编程和训练来执行一组范围狭窄的操作。例如，用于对象分类的 AI 算法无法执行自然语言处理。Google 搜索是一种窄 AI，预测分析或虚拟助理也是窄 AI。

人工通用智能 (AGI) 是指机器可以像人类一样“感知、思考和行动”。AGI 目前不存在。下一个等级将是人工超级智能 (ASI)，即机器可以在所有方面发挥出优于人类的功能。

人工智能训练模型
企业在谈论 AI 时，通常会谈论“训练数据”。“训练数据”是什么意思呢？请记住，拥有有限记忆的人工智能是利用新数据进行训练，进而随着时间的推移而改进的 AI。机器学习是人工智能的一个细分领域，它使用算法训练数据来获取结果。

概括来讲，机器学习中经常使用三种学习模型：

监督式学习：一种使用带标签的训练数据（结构化数据）将特定输入映射到输出的机器学习模型。简单来说，如需训练可识别猫的图片的算法，应向其提供标记为猫的图片。

非监督式学习：一种根据无标签数据（非结构化数据）学习模式的机器学习模型。与监督式学习不同，最终结果不会提前知道。相反，算法会从数据中学习，并根据属性将数据分类为多个组。例如，非监督式学习擅长模式匹配和描述性建模。

除了监督式和非监督式学习之外，人们通常还会采用一种名为“半监督式学习”的混合方法，其中只会对部分数据添加标签。在半监督式学习中，最终结果是已知的，但算法必须决定如何组织和构造数据以获得期望的结果。

强化学习：一种可以广义地描述为“边做边学”的机器学习模型。“代理”通过试错（反馈环）学习执行规定的任务，直到其表现处于理想范围内。当代理出色执行任务时，它会获得正强化；当代理表现不佳时，它会获得负强化。强化学习的一个例子是教机械手捡球。

常见的人工神经网络类型
AI 中一种常见的训练模型是人工神经网络（一种松散地基于人脑的模型）。

神经网络是人工神经元系统（有时称为感知机），该系统是用于对数据进行分类和分析的计算节点。数据被输入神经网络的第一层，每个感知机都会做出决定，然后将该信息传递到下一层的多个节点。超过三层的训练模型称为“深度神经网络”或“深度学习”。某些现代神经网络有数百或数千层。最终感知机的输出完成神经网络的任务集，例如对对象进行分类或在数据中查找模式。

您可能会遇到的一些最常见的人工神经网络类型包括：

前馈神经网络 (FF) 是一种最早的神经网络形式，其中数据单向流过人工神经元层，直到获得输出。在现代，大多数前馈神经网络都被视为具有多个层（以及多个“隐藏”层）的“深度前馈神经网络”。前馈神经网络通常与称为“反向传播算法”的纠错算法配对使用。简单说来，该算法从神经网络的结果开始，然后一直反向工作到开始，从而发现错误以提高神经网络的准确率。许多简单但强大的神经网络都是深度前馈神经网络。

循环神经网络 (RNN) 是一种与前馈神经网络不同的神经网络，它们通常使用时序数据或涉及序列的数据。与在网络的每个节点中使用权重的前馈神经网络不同，循环神经网络对前一层发生的事情具有“记忆”，这取决于当前层的输出。例如，执行自然语言处理时，RNN 可以“记住”一个句子中使用的其他字词。RNN 通常用于语音识别、翻译和图片说明。

长/短期记忆 (LSTM) 是一种高级形式的 RNN，它可以使用记忆来“记住”先前的层中发生的事情。RNN 和 LSTM 之间的区别在于，LSTM 可以通过使用“记忆单元”来记住几层之前发生的事情。LSTM 常用于语音识别和预测。

卷积神经网络 (CNN) 包含现代人工智能中一些最常见的神经网络。CNN 最常用于图像识别，它使用几个不同的层（一个卷积层，然后是一个 pooling 层），这些层在将图像重新组合在一起（在全连接层中）之前过滤图像的不同部分。较早的卷积层可能会寻找图像的简单特征，例如颜色和边缘，然后在附加层中寻找更复杂的特征。

生成对抗网络 (GAN) 涉及两个神经网络，它们在游戏中会相互竞争，最终提高输出的准确率。一个网络（生成器）创建另一个网络（判别器）尝试证明真假的样本。GAN 用于制作逼真的图片，甚至用于制作艺术品。
"""

# 调用生成 Quiz 的函数
quizzes = generate_quiz_with_deepseek(test_text)

# 打印生成的 Quiz
for quiz in quizzes:
    print(f"Quiz ID: {quiz['quiz_id']}")
    print(f"Question: {quiz['quiz']['question']}")
    print(f"Options: {quiz['quiz']['options']}")
    print(f"Answer: {quiz['quiz']['answer']}")
    print()